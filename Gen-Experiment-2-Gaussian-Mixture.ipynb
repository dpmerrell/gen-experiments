{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Gen` Experiments\n",
    "# II. Gaussian Mixture Model\n",
    "\n",
    "(c) David Merrell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Gen\n",
    "using PyPlot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "In this notebook we'll build a Gaussian mixture model, condition it on some (simulated) data, and infer the posterior distribution of the cluster centers.\n",
    "\n",
    "We'll assume the number of components (clusters) is known.\n",
    "Note: If we didn't know the number of clusters, then we could use some other model -- e.g., Dirichlet Process clustering. I have another notebook for that.\n",
    "\n",
    "For simplicity's sake, we'll assume the clusters all have equal probability.\n",
    "(Otherwise we would use a Dirichlet prior to model the differing cluster probabilities)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@gen function gauss_mix(n_clusters::Int64, n_samples::Int64)\n",
    "    \n",
    "    cluster_means = [@trace(normal(0.0, 10.0), :means => i) for i=1:n_clusters]\n",
    "    cluster_spreads = [@trace(gamma(1.0, 1.0), :spreads => i) for i=1:n_clusters]\n",
    "    cluster_probs = fill(1.0/n_clusters, n_clusters)\n",
    "    \n",
    "    z = zeros(n_samples, 1)\n",
    "    \n",
    "    for j=1:n_samples\n",
    "        c = @trace(categorical(cluster_probs), :cluster => j)\n",
    "        z[j] = @trace(normal(cluster_means[c], cluster_spreads[c]), :z => j)\n",
    "    end\n",
    "    \n",
    "    return z\n",
    "\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity check: simulate & visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 1000\n",
    "n_clusters = 4\n",
    "    \n",
    "tr = simulate(gauss_mix, (n_clusters, n_samples));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "function plot_choices(zs, means, assignments)\n",
    "    \n",
    "    z_vecs = [zs[assignments .== i] for i=1:length(unique(assignments))]\n",
    "    hist(z_vecs, Int(round(sqrt(n_samples))), histtype=\"barstacked\", normed=true)\n",
    "\n",
    "    for (i, mean) in enumerate(means)\n",
    "        plot([mean; mean], [0; n_samples], color=\"k\")\n",
    "    end\n",
    "    \n",
    "end;\n",
    "\n",
    "\n",
    "function plot_trace(tr)\n",
    "    \n",
    "    zs = [tr[:z => j] for j=1:n_samples];\n",
    "    means = [tr[:means => i] for i=1:n_clusters];\n",
    "    assignments = [tr[:cluster => j] for j=1:n_samples]\n",
    "    \n",
    "    plot_choices(zs, means, assignments)\n",
    "\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "Figure(PyObject <matplotlib.figure.Figure object at 0x7f73162357b8>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_trace(tr)\n",
    "ylim(0,0.5)\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian mixture models are difficult\n",
    "\n",
    "The Gaussian mixture model poses some challenges for Bayesian inference.\n",
    "* Identifiability issues:\n",
    "    - Cluster labeling is arbitrary. That is: when we sample cluster locations multiple times, there is ambiguity regarding which location belongs to which hidden gaussian.\n",
    "    - If two hidden gaussians are located very near each other -- i.e., the distance between their means is much smaller than either of their standard deviations -- then they will be practically indistinguishable. (This seems more like a mathematical curiosity than a practical modeling issue; if our inference method consistently yields co-located clusters, then we're probably assuming too many clusters.)\n",
    "    - Michael Betancourt (one of the brains behind Stan) wrote a nice post about these issues: https://mc-stan.org/users/documentation/case-studies/identifying_mixture_models.html. I recommend reading it if you get a chance. His solution, in essence, consists of using very strong priors. We will use a different strategy -- one that highlights the power of Gen's \"programmable inference\" design philosophy.\n",
    "* Sampling challenges:\n",
    "    - If we use something very naive -- like importance sampling -- to infer posteriors on the locations, then we will have very inefficient inference. The probability of $k$ randomly sampled locations each landing near a hidden gaussian is very small. \n",
    "    - If we do something smarter, like Metropolis-Hastings, then we have another set of issues to deal with -- multimodality. Think of it this way: if we have $k$ cluster locations going on a random walk, then there is little probability that each of the hidden gaussians will end up with exactly one of them. It's more probable that some gaussians will end up with more than one of our randomly-walking locations, and that other hidden gaussians will end up with none. But these non-optimal arrangements are still local maxima in probability, so it will be difficult to escape those arrangements and find the correct one.  \n",
    "\n",
    "\n",
    "## Solution: Heuristic-guided sampling\n",
    "\n",
    "There are strategies to solve these problems:\n",
    "* We can keep the sampled locations in sorted order. Since the hidden gaussians must themselves be ordered, this establishes an unambiguous assignment of sampled locations to hidden gaussians.\n",
    "    - Note: this idea of \"sorting\" relies on the fact that we have 1-dimensional data. However, we can extend this strategy to higher dimensions by using a *linear assignment* to map new samples to old samples, maintaining a consistent assignment from the samples to regions of space.\n",
    "* We can ameliorate the multimodality of MCMC by using a heuristic to *guide* our sampling toward regions of high probability. For example, we can use K-means clustering to initialize *and periodically reset* our markov chain.\n",
    "    - Note: K-means may also fall prey to multi-modality. However, it is a relatively inexpensive heuristic that allows us to efficiently visit the different modes (even if they're far away from each other).\n",
    "    - Note: if you're wondering why it's okay to use a heuristic like K-means during MCMC, see this excellent preprint: https://arxiv.org/abs/1801.03612 \n",
    "\n",
    "So our inference task requires a highly specialized sampling strategy. \n",
    "Most PPLs would have difficulty managing this.\n",
    "In contrast, `Gen`'s \"programmable inference\" philosophy handles it perfectly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-means implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Statistics\n",
    "\n",
    "function mean_update(data, cluster_assignments, k)\n",
    "    return [mean(data[cluster_assignments .== i]) for i=1:k]\n",
    "end\n",
    "\n",
    "function cluster_update(data, means)\n",
    "    \n",
    "    dists = map(abs, data .- transpose(means))\n",
    "    min_inds = argmin(dists, dims=2)\n",
    "    \n",
    "    return [min_inds[i][2] for i=1:length(min_inds)]\n",
    "end\n",
    "\n",
    "\n",
    "function kmeans(data::Array{Float64,1}, k::Int64, max_iter::Int64=1000)\n",
    "    \n",
    "    # random initialization\n",
    "    cluster_assignments = zeros(size(data)[1])\n",
    "    means = rand(data, k)\n",
    "    \n",
    "    i = 1\n",
    "    while i <= max_iter\n",
    "        \n",
    "        cluster_assignments = cluster_update(data, means)\n",
    "        new_means = mean_update(data, cluster_assignments, k)\n",
    "        \n",
    "        if new_means == means\n",
    "            break\n",
    "        end\n",
    "        \n",
    "        means = new_means\n",
    "        i += 1\n",
    "        \n",
    "    end\n",
    "    \n",
    "    # Sort the means in order to ameliorate\n",
    "    # identifiability issues.\n",
    "    srt_inds = sortperm(means)\n",
    "    inv_map = zeros(size(srt_inds))\n",
    "    for (i, ind) in enumerate(srt_inds)importance sampling\n",
    "        inv_map[ind] = i\n",
    "    end\n",
    "    ca = map(x->inv_map[x], cluster_assignments)\n",
    "    \n",
    "    return means[srt_inds], ca\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proposal distributions (and other functions for updating the trace)\n",
    "\n",
    "Our inference procedure will use these functions to help generate samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This proposal uses k-means to reset the \n",
    "# cluster locations.\n",
    "@gen function kmean_proposal(tr, n_clusters, dataset, noise)\n",
    "    \n",
    "    means, assignments = kmeans(dataset, n_clusters)\n",
    "    for i=1:n_clusters\n",
    "        @trace(normal(means[i], noise), :means => i)\n",
    "    end\n",
    "    \n",
    "    \n",
    "end\n",
    "\n",
    "function initialize_trace_kmeans(dataset, n_clusters)\n",
    "    \n",
    "    init_settings = Gen.choicemap()\n",
    "    means, assignments = kmeans(dataset, n_clusters, max_iters)\n",
    "    for i=1:n_clusters\n",
    "        init_settings[:means => i] = means[i]\n",
    "    end\n",
    "    for j=1:length(dataset)\n",
    "        init_settings[:cluster => j] = assignments[j]\n",
    "        init_settings[:z => j] = dataset[j]\n",
    "    end\n",
    "       \n",
    "    tr, _ = Gen.generate(gauss_mix, (n_clusters, length(dataset)), init_settings)\n",
    "    \n",
    "    return tr\n",
    "end\n",
    "\n",
    "# A proposal distribution for the cluster locations\n",
    "@gen function cluster_mean_proposal(tr, n_clusters)\n",
    "    for i=1:n_clusters\n",
    "        @trace(normal(tr[:means => i], 0.25), :means => i)\n",
    "    end\n",
    "end\n",
    "\n",
    "\n",
    "# We simply resample the clusters' standard deviations\n",
    "@gen function cluster_spread_proposal(tr, n_clusters)\n",
    "    for i=1:n_clusters\n",
    "        @trace(gamma(1.0, 1.0), :spreads => i)\n",
    "    end\n",
    "end\n",
    "\n",
    "# We update the cluster assignment of each data-point in a \n",
    "# Gibbs sampling fashion.\n",
    "function cluster_assignment_gibbs_update(tr, n_clusters, n_data)\n",
    "    \n",
    "    # The cluster assignments only ever interact with the \n",
    "    # cluster centers in sorted order.\n",
    "    centers = [tr[:means => i] for i=1:n_clusters]\n",
    "    srt_inds = sortperm(centers)\n",
    "    centers = centers[srt_inds]\n",
    "    spreads = [tr[:spreads => i] for i=1:n_clusters][srt_inds]\n",
    "    \n",
    "    new_assignments = Gen.choicemap()\n",
    "    \n",
    "    for j=1:n_data\n",
    "        unnorm_probs = [ exp(-0.5* (tr[:z => j] - centers[i])^2 / (spreads[i]^2)) / spreads[i] for i=1:n_clusters]\n",
    "        new_assignments[:cluster => j] = categorical(unnorm_probs ./ sum(unnorm_probs))\n",
    "    end\n",
    "    \n",
    "    new_tr, _, _, _ = Gen.update(tr, (n_clusters, n_data), (), new_assignments)\n",
    "    return new_tr\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A single step of the MCMC sampler:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function mcmc_sample(tr, n_clusters, n_data)\n",
    "    \n",
    "    tr, _ = Gen.mh(tr, cluster_mean_proposal, (n_clusters,))\n",
    "    tr, _ = Gen.mh(tr, cluster_spread_proposal, (n_clusters,))\n",
    "    tr = cluster_assignment_gibbs_update(tr, n_clusters, n_data)\n",
    "    \n",
    "    return tr\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function smarter_mcmc_inference(tr, n_samples, n_clusters, n_data, burnin=10, thinning=10)\n",
    "    \n",
    "    means = zeros(n_samples, n_clusters)\n",
    "    spreads = zeros(n_samples, n_clusters)\n",
    "    assignments = zeros(n_data, n_clusters)\n",
    "    \n",
    "    for b=1:burnin\n",
    "        tr = smarter_mcmc_sample(tr, n_clusters, n_data)\n",
    "    end\n",
    "    println(\"finished burnin; now sampling...\")\n",
    "    for s=1:n_samples\n",
    "        for t=1:thinning\n",
    "            tr = smarter_mcmc_sample(tr, n_clusters, n_data)\n",
    "        end\n",
    "        \n",
    "        for i=1:n_clusters\n",
    "            means[s,i] = tr[:means => i]\n",
    "            spreads[s,i] = tr[:spreads => i]\n",
    "        end\n",
    "        for j=1:n_data\n",
    "            assignments[j,tr[:cluster => j]] += 1\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    println(\"postprocessing...\")\n",
    "    for s=1:n_samples\n",
    "        srt_inds = sortperm(means[s,:])\n",
    "        means[s,:] = means[s,srt_inds]\n",
    "        spreads[s,:] = spreads[s,srt_inds]\n",
    "    end\n",
    "        \n",
    "    return means, spreads, assignments\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = initialize_trace_kmeans(zs, 4)\n",
    "plot_trace(tr)\n",
    "ylim(0,30)\n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means, spreads, assignments = smarter_mcmc_inference(tr, 1000, 4, length(zs), 100, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(means[:,4])\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference: k-means-guided MCMC\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.2.0",
   "language": "julia",
   "name": "julia-1.2"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
